#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
5a_map_streamlit.py
-------------------------------------------------
Author : Will
Purpose: Interactive map + AI Q&A for China's National 5Aâ€‘rated tourist attractions
    â€¢ Top banner: â€œå…¨å›½ 5A çº§æ™¯ç‚¹â€ + subâ€‘title â€œby Willâ€
    â€¢ Sidebar: province / city multiselect â†’ map updates in real time
    â€¢ Folium map: CartoDBâ€‘Positron style + MarkerCluster + minimalist circle icons
    â€¢ Bottom panel: DeepSeekâ€‘powered chat assistant (answers 5A spot questions)
    â€¢ Responsive layout: desktop & mobile

Run      :  streamlit run 5a_map_streamlit.py
Requires :  pip install streamlit pandas folium requests python-dotenv
-------------------------------------------------
"""

from pathlib import Path

import streamlit as st
import pandas as pd
import folium
from folium.plugins import MarkerCluster, BeautifyIcon
from streamlit_folium import st_folium

import os
import requests
import json
import threading, queue, time
from dotenv import load_dotenv, find_dotenv

load_dotenv(find_dotenv())  # load variables from .env if present
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è·¯å¾„é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = Path(__file__).resolve().parent
DATA_CSV = BASE_DIR / "5A_scenic_geo_places.csv"

# DeepSeek API Key (set DEEPSEEK_API_KEY in your shell or .env)
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
if not DEEPSEEK_API_KEY:
    st.warning("æœªæ£€æµ‹åˆ° DEEPSEEK_API_KEYï¼ŒèŠå¤©åŠŸèƒ½å°†æ— æ³•ä½¿ç”¨ã€‚", icon="âš ï¸")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¡µé¢è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="å…¨å›½5Açº§æ™¯ç‚¹", layout="wide")

st.markdown(
    """
    <h1 style='margin-bottom:0.2em'>5Açº§æ™¯ç‚¹ï½œä¸ºäº†ä¸‹ä¸€æ¬¡æ›´å¥½åœ°å‡ºå‘ï¼â›°ï¸ğŸ”ï¸ğŸ—»</h1>
    <p style='color:gray;margin:0'>by&nbsp;Will</p>
    """,
    unsafe_allow_html=True,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¯»å–æ•°æ® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_df(path: Path, mtime: float) -> pd.DataFrame:   # mtime å‚ä¸ key
    df_ = pd.read_csv(path)
    return df_.dropna(subset=["longitude", "latitude"])

df = load_df(DATA_CSV, DATA_CSV.stat().st_mtime)         # include mtime so cache invalidates on file update

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å·¦æ ç­›é€‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ç­›é€‰")
    provinces = sorted(df["province"].dropna().unique())
    sel_provinces = st.multiselect("çœä»½", provinces, default=provinces)

    cities = sorted(
        df.loc[df["province"].isin(sel_provinces), "city"].dropna().unique()
    )
    sel_cities = st.multiselect("åŸå¸‚", cities, default=cities)

MUNICIPALITIES = {"åŒ—äº¬å¸‚", "ä¸Šæµ·å¸‚", "å¤©æ´¥å¸‚", "é‡åº†å¸‚"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ„å»ºè¿‡æ»¤æ©ç  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mask_prov = df["province"].isin(sel_provinces)

# ç›´è¾–å¸‚ï¼šè‹¥çœä»½è¢«é€‰ä¸­ï¼Œåˆ™å¿½ç•¥ city å­—æ®µï¼Œç›´æ¥å…¨éƒ¨åŒ…å«
muni_selected = set(sel_provinces) & MUNICIPALITIES
mask_city = (
    df["city"].isin(sel_cities) |           # æ™®é€šåŸå¸‚æ­£å¸¸åŒ¹é…
    df["province"].isin(muni_selected)      # é€‰ä¸­çš„ç›´è¾–å¸‚å…¨é‡åŒ¹é…
)

df_view = df[mask_prov & mask_city]

st.info(f"å…± **{len(df_view)}** ä¸ªæ™¯ç‚¹", icon="ğŸš—")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç”ŸæˆåŠ¨æ€ Folium â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_map(df_subset: pd.DataFrame) -> folium.Map:
    # ç©ºé›†åˆ™å®šä½ä¸­å›½ä¸­å¿ƒ
    if df_subset.empty:
        m = folium.Map(location=[35.0, 103.8], zoom_start=4, tiles="CartoDB positron")
        return m

    m = folium.Map(
        location=[df_subset["latitude"].mean(), df_subset["longitude"].mean()],
        zoom_start=5,
        tiles="CartoDB positron",
    )
    cluster = MarkerCluster().add_to(m)

    for _, row in df_subset.iterrows():
        popup = (
            f'<div style="padding:6px 10px;border-radius:8px;'
            f'background:#ffffff;box-shadow:0 1px 4px rgba(0,0,0,.15);'
            f'font-weight:500;font-size:0.75em;">{row["scenic"]}'
            f'<br/><small style="font-size:0.4em;">{row["province"]}Â·{row["city"]}</small></div>'
        )
        folium.Marker(
            location=(row["latitude"], row["longitude"]),
            popup=folium.Popup(popup, max_width=250),
            icon=BeautifyIcon(
                icon_shape="circle",
                border_color="#4a4a4a",
                border_width=1,
                background_color="#f5f5f5",
                icon_size=[12, 12],
            ),
        ).add_to(cluster)

    return m


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DeepSeek Chat Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_END_TOKEN = "__END_OF_STREAM__"
def ask_deepseek(prompt: str, history: list[tuple[str, str]], temperature: float = 1.0):
    """
    Call DeepSeek Chat Completion API and stream the answer.
    Only uses the prompt text; model & parameters are fixed for simplicity.
    """
    if not DEEPSEEK_API_KEY:
        yield "âš ï¸ æœªè®¾ç½® API Keyï¼Œæ— æ³•è°ƒç”¨ DeepSeekã€‚"
        return

    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
    }
    # Build message history: system prompt + last 6 turns to conserve tokens
    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸­å›½æ—…è¡Œé¡¾é—®ï¼Œä¸“é—¨å›ç­”å…³äºå…¨å›½5Açº§æ™¯ç‚¹çš„é—®ç­”ï¼Œå¹¶ä¸”åº”å‚è€ƒä¸Šä¸‹æ–‡è¿ç»­å›ç­”ã€‚"}]

    # Append recent history
    for role, content in history[-6:]:
        messages.append({"role": role, "content": content})

    # Current user question
    messages.append({"role": "user", "content": prompt})

    payload = {
        "model": "deepseek-reasoner",
        "messages": messages,
        "max_tokens": 1600,
        "temperature": temperature,
        "stream": True
    }

    try:
        with requests.post(url, headers=headers, json=payload, stream=True, timeout=120) as resp:
            resp.raise_for_status()
            full_answer = ""
            for line in resp.iter_lines():
                if not line or line == b": ping":
                    continue  # skip keepâ€‘alive

                if line.startswith(b"data: "):
                    data_str = line[6:]
                    # Stream finished
                    if data_str == b"[DONE]":
                        break
                    # Attempt to parse JSON; skip invalid chunks
                    try:
                        line_json = json.loads(data_str)
                        delta = (line_json.get("choices")
                                 and line_json["choices"][0]["delta"].get("content"))
                        if delta:
                            full_answer += delta
                            yield delta
                    except json.JSONDecodeError:
                        continue  # ignore malformed line
            return full_answer
    except Exception as exc:
        yield f"âŒ è°ƒç”¨ DeepSeek å¤±è´¥: {exc}"


fmap = build_map(df_view)
st_folium(fmap, use_container_width=True, height=680)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ™¯åŒºé—®ç­”å¯¹è¯æ¡† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.divider()
st.subheader("ğŸ¤ 5A æ™¯ç‚¹é—®ç­”ï½œAI")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Show chat history
for role, msg in st.session_state.chat_history:
    if role == "user":
        st.chat_message("user").write(msg)
    else:
        st.chat_message("assistant").write(msg)

# Input box at bottom of the page
user_question = st.chat_input("å…³äº 5A æ™¯ç‚¹æƒ³é—®ä»€ä¹ˆï¼Ÿ")
if user_question:
    # --- æŠŠç”¨æˆ·é—®é¢˜å†™å…¥ç•Œé¢ & å†å² ---
    st.session_state.chat_history.append(("user", user_question))
    st.chat_message("user").write(user_question)

    # --- å…ˆæ˜¾ç¤ºâ€œæ€è€ƒä¸­â€å ä½ ---
    assistant_container = st.chat_message("assistant")
    with assistant_container:
        thinking_slot = st.empty()
        thinking_slot.write("ğŸ¤” Thinking...")

    # --- å¯åŠ¨åå°çº¿ç¨‹æµå¼è·å–ç­”æ¡ˆ ---
    q: queue.Queue[str] = queue.Queue()

    # Capture current history outside the thread (session_state is not threadâ€‘safe)
    history_snapshot = list(st.session_state.chat_history)

    def _worker(history_local: list[tuple[str, str]]):
        """Background thread: stream from DeepSeek and push to queue."""
        try:
            for chunk in ask_deepseek(user_question, history_local, temperature=0.3):
                q.put(chunk or "")  # enqueue even empty chunk
            q.put(_END_TOKEN)
        except Exception as exc:
            q.put(f"âŒ DeepSeek é”™è¯¯: {exc}")
            q.put(_END_TOKEN)

    threading.Thread(target=_worker, args=(history_snapshot,), daemon=True).start()

    # --- å…ˆé˜»å¡ç›´åˆ°æ‹¿åˆ°ç¬¬ä¸€å—å†…å®¹ï¼Œä»¥ä¾¿ä¿æŒâ€œThinking...â€æ›´ä¹… ---
    streamed_answer = ""
    try:
        first_chunk = q.get(timeout=25)  # æœ€å¤šç­‰ 25 ç§’
    except queue.Empty:
        thinking_slot.markdown("âŒ 25 ç§’æ— å“åº”ï¼Œè¯·ç¨åå†è¯•")
        st.session_state.chat_history.append(("assistant", "25 ç§’æ— å“åº”ï¼Œè¯·ç¨åå†è¯•"))
        first_chunk = _END_TOKEN
    if first_chunk == _END_TOKEN:
        thinking_slot.markdown("â“ æœªæ”¶åˆ°å›ç­”")
        st.session_state.chat_history.append(("assistant", "æœªæ”¶åˆ°å›ç­”"))
    else:
        streamed_answer += first_chunk
        thinking_slot.markdown(streamed_answer + "â–Œ")

        # --- åç»­éé˜»å¡è½®è¯¢ï¼Œç»§ç»­æ‹¼æ¥ ---
        cursor_visible = True
        last_update = time.time()

        while True:
            try:
                chunk = q.get(timeout=0.1)
                if chunk == _END_TOKEN:
                    break
                streamed_answer += chunk
                thinking_slot.markdown(streamed_answer + ("â–Œ" if cursor_visible else ""))
            except queue.Empty:
                # toggle cursor every 0.5 s for blink effect
                if time.time() - last_update > 0.5:
                    cursor_visible = not cursor_visible
                    thinking_slot.markdown(streamed_answer + ("â–Œ" if cursor_visible else ""))
                    last_update = time.time()

        # --- å†™å…¥å†å²å¹¶æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ ---
        thinking_slot.markdown(streamed_answer)
        st.session_state.chat_history.append(("assistant", streamed_answer))